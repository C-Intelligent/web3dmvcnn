{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "120671cf",
   "metadata": {},
   "source": [
    "## mvcnn\n",
    "### 一些基础知识\n",
    "#### mean 均值  std 方差\n",
    "- 本数据集:\n",
    "    - means : [0.81662318, 0.81662318, 0.81662318]\n",
    "    - std: [0.24117189, 0.24117189, 0.24117189]\n",
    "\n",
    "### 其他\n",
    "- 需要计算方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d8de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os,shutil,json\n",
    "import argparse\n",
    "\n",
    "from tools.Trainer import ModelNetTrainer\n",
    "from tools.ImgDataset import MultiviewImgDataset, SingleImgDataset\n",
    "from models.MVCNN import MVCNN, SVCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5567629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(log_dir):\n",
    "    # make summary folder\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.mkdir(log_dir)\n",
    "    else:\n",
    "        print('WARNING: summary folder already exists!! It will be overwritten!!')\n",
    "        shutil.rmtree(log_dir)\n",
    "        os.mkdir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f43e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: summary folder already exists!! It will be overwritten!!\n"
     ]
    }
   ],
   "source": [
    "name = 'mvcnn'\n",
    "# num_models = 1000\n",
    "num_models = 0\n",
    "weight_decay = 0.001 \n",
    "num_views = 12 \n",
    "cnn_name = 'vgg11'\n",
    "no_pretraining = False\n",
    "lr = 5e-5\n",
    "bs = 64\n",
    "batchSize = bs\n",
    "svcnn_bs = 64\n",
    "# web_shapent55_renamed_0.2   modelnet40_images_new_12x\n",
    "train_path = 'web_shapent55_renamed_0.2/*/train'\n",
    "val_path = 'web_shapent55_renamed_0.2/*/test'\n",
    "\n",
    "pretraining = not no_pretraining\n",
    "log_dir = name\n",
    "create_folder(name)\n",
    "# config_f = open(os.path.join(log_dir, 'config.json'), 'w')\n",
    "# json.dump(vars(args), config_f)\n",
    "# config_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52994a61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_files: 287700\n",
      "num_val_files: 37404\n",
      "num_train_files: 287700\n",
      "num_val_files: 37404\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "n_models_train = num_models*num_views\n",
    "\n",
    "train_dataset = SingleImgDataset(train_path, scale_aug=False, rot_aug=False, num_models=n_models_train, num_views=num_views)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=svcnn_bs, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = SingleImgDataset(val_path, scale_aug=False, rot_aug=False, test_mode=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=svcnn_bs, shuffle=False, num_workers=0)\n",
    "print('num_train_files: '+str(len(train_dataset.filepaths)))\n",
    "print('num_val_files: '+str(len(val_dataset.filepaths)))\n",
    "\n",
    "train_dataset = MultiviewImgDataset(train_path, scale_aug=False, rot_aug=False, num_models=n_models_train, num_views=num_views)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize, shuffle=False, num_workers=0)# shuffle needs to be false! it's done within the trainer\n",
    "\n",
    "val_dataset = MultiviewImgDataset(val_path, scale_aug=False, rot_aug=False, num_views=num_views)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batchSize, shuffle=False, num_workers=0)\n",
    "print('num_train_files: '+str(len(train_dataset.filepaths)))\n",
    "print('num_val_files: '+str(len(val_dataset.filepaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "511c3037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59beb5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]]],\n",
       "\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]],\n",
       "\n",
       "\n",
       "         [[[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]],\n",
       "\n",
       "          [[0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           ...,\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604],\n",
       "           [0.7604, 0.7604, 0.7604,  ..., 0.7604, 0.7604, 0.7604]]]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_num = 200\n",
    "meta_val_dataset = MultiviewImgDataset(val_path, scale_aug=False, rot_aug=False, num_views=num_views)\n",
    "meta_val_dataset.val_set_select(meta_num)\n",
    "V,C,H,W = meta_val_dataset[0][1].size()\n",
    "meta_data_x = torch.Tensor(meta_num, V,C,H,W)\n",
    "meta_data_y = torch.Tensor(meta_num)\n",
    "for i, m in enumerate(meta_val_dataset):\n",
    "    meta_data_y[i] = m[0]\n",
    "    meta_data_x[i] = m[1]\n",
    "meta_data_y = meta_data_y.int()\n",
    "meta_data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3feb8fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13, dtype=torch.int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ece4f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_47718/1344727012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_val_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "print(meta_val_loader[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a6f485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next(iter(meta_val_loader))\n",
    "\n",
    "# data = enumerate(meta_val_loader)\n",
    "list(meta_val_loader)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd057bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: summary folder already exists!! It will be overwritten!!\n",
      "num_train_files: 279972\n",
      "num_val_files: 37404\n"
     ]
    }
   ],
   "source": [
    "# STAGE 1\n",
    "log_dir = name+'_stage_1'\n",
    "create_folder(log_dir)\n",
    "cnet = SVCNN(name, nclasses=55, pretraining=pretraining, cnn_name=cnn_name)\n",
    "\n",
    "optimizer = optim.Adam(cnet.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "n_models_train = num_models*num_views\n",
    "\n",
    "train_dataset = SingleImgDataset(train_path, scale_aug=False, rot_aug=False, num_models=n_models_train, num_views=num_views)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=svcnn_bs, shuffle=True, num_workers=0)\n",
    "\n",
    "val_dataset = SingleImgDataset(val_path, scale_aug=False, rot_aug=False, test_mode=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=svcnn_bs, shuffle=False, num_workers=0)\n",
    "print('num_train_files: '+str(len(train_dataset.filepaths)))\n",
    "print('num_val_files: '+str(len(val_dataset.filepaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed85494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 1: train_loss 4.163; train_acc 0.031\n",
      "epoch 1, step 2: train_loss 4.015; train_acc 0.031\n",
      "epoch 1, step 3: train_loss 3.995; train_acc 0.031\n",
      "epoch 1, step 4: train_loss 4.020; train_acc 0.000\n",
      "epoch 1, step 5: train_loss 4.009; train_acc 0.031\n",
      "epoch 1, step 6: train_loss 4.041; train_acc 0.000\n",
      "epoch 1, step 7: train_loss 4.140; train_acc 0.000\n",
      "epoch 1, step 8: train_loss 3.967; train_acc 0.031\n",
      "epoch 1, step 9: train_loss 3.957; train_acc 0.062\n",
      "epoch 1, step 10: train_loss 3.966; train_acc 0.000\n",
      "epoch 1, step 11: train_loss 3.864; train_acc 0.000\n",
      "epoch 1, step 12: train_loss 3.981; train_acc 0.062\n",
      "epoch 1, step 13: train_loss 3.859; train_acc 0.062\n",
      "epoch 1, step 14: train_loss 3.856; train_acc 0.125\n",
      "epoch 1, step 15: train_loss 3.891; train_acc 0.125\n",
      "epoch 1, step 16: train_loss 3.972; train_acc 0.031\n",
      "epoch 1, step 17: train_loss 3.850; train_acc 0.031\n",
      "epoch 1, step 18: train_loss 3.906; train_acc 0.094\n",
      "epoch 1, step 19: train_loss 3.857; train_acc 0.062\n",
      "epoch 1, step 20: train_loss 3.756; train_acc 0.125\n",
      "epoch 1, step 21: train_loss 3.744; train_acc 0.125\n",
      "epoch 1, step 22: train_loss 3.709; train_acc 0.094\n",
      "epoch 1, step 23: train_loss 3.880; train_acc 0.094\n",
      "epoch 1, step 24: train_loss 3.884; train_acc 0.062\n",
      "epoch 1, step 25: train_loss 4.045; train_acc 0.031\n",
      "epoch 1, step 26: train_loss 3.761; train_acc 0.062\n",
      "epoch 1, step 27: train_loss 3.875; train_acc 0.031\n",
      "epoch 1, step 28: train_loss 3.968; train_acc 0.031\n",
      "epoch 1, step 29: train_loss 3.844; train_acc 0.094\n",
      "epoch 1, step 30: train_loss 3.770; train_acc 0.062\n",
      "epoch 1, step 31: train_loss 3.847; train_acc 0.062\n",
      "epoch 1, step 32: train_loss 3.752; train_acc 0.094\n",
      "epoch 1, step 33: train_loss 3.884; train_acc 0.031\n",
      "epoch 1, step 34: train_loss 3.691; train_acc 0.062\n",
      "epoch 1, step 35: train_loss 3.702; train_acc 0.094\n",
      "epoch 1, step 36: train_loss 4.042; train_acc 0.062\n",
      "epoch 1, step 37: train_loss 3.530; train_acc 0.094\n",
      "epoch 1, step 38: train_loss 3.622; train_acc 0.156\n",
      "epoch 1, step 39: train_loss 3.638; train_acc 0.188\n",
      "epoch 1, step 40: train_loss 3.554; train_acc 0.062\n",
      "epoch 1, step 41: train_loss 3.296; train_acc 0.312\n",
      "epoch 1, step 42: train_loss 3.501; train_acc 0.125\n",
      "epoch 1, step 43: train_loss 3.599; train_acc 0.125\n",
      "epoch 1, step 44: train_loss 3.802; train_acc 0.094\n",
      "epoch 1, step 45: train_loss 3.754; train_acc 0.094\n",
      "epoch 1, step 46: train_loss 4.002; train_acc 0.031\n",
      "epoch 1, step 47: train_loss 3.649; train_acc 0.094\n",
      "epoch 1, step 48: train_loss 3.798; train_acc 0.094\n",
      "epoch 1, step 49: train_loss 3.920; train_acc 0.094\n",
      "epoch 1, step 50: train_loss 3.748; train_acc 0.031\n",
      "epoch 1, step 51: train_loss 3.853; train_acc 0.062\n",
      "epoch 1, step 52: train_loss 3.496; train_acc 0.250\n",
      "epoch 1, step 53: train_loss 3.798; train_acc 0.062\n",
      "epoch 1, step 54: train_loss 3.664; train_acc 0.125\n",
      "epoch 1, step 55: train_loss 3.576; train_acc 0.156\n",
      "epoch 1, step 56: train_loss 3.781; train_acc 0.000\n",
      "epoch 1, step 57: train_loss 3.573; train_acc 0.094\n",
      "epoch 1, step 58: train_loss 3.721; train_acc 0.156\n",
      "epoch 1, step 59: train_loss 3.484; train_acc 0.156\n",
      "epoch 1, step 60: train_loss 3.925; train_acc 0.062\n",
      "epoch 1, step 61: train_loss 3.416; train_acc 0.188\n",
      "epoch 1, step 62: train_loss 3.629; train_acc 0.125\n",
      "epoch 1, step 63: train_loss 3.605; train_acc 0.031\n",
      "epoch 1, step 64: train_loss 3.375; train_acc 0.125\n",
      "epoch 1, step 65: train_loss 3.358; train_acc 0.125\n",
      "epoch 1, step 66: train_loss 3.447; train_acc 0.156\n",
      "epoch 1, step 67: train_loss 3.585; train_acc 0.125\n",
      "epoch 1, step 68: train_loss 3.952; train_acc 0.094\n",
      "epoch 1, step 69: train_loss 3.652; train_acc 0.156\n",
      "epoch 1, step 70: train_loss 3.852; train_acc 0.125\n",
      "epoch 1, step 71: train_loss 3.710; train_acc 0.031\n",
      "epoch 1, step 72: train_loss 3.504; train_acc 0.125\n",
      "epoch 1, step 73: train_loss 3.334; train_acc 0.250\n",
      "epoch 1, step 74: train_loss 3.492; train_acc 0.188\n",
      "epoch 1, step 75: train_loss 3.713; train_acc 0.094\n",
      "epoch 1, step 76: train_loss 3.620; train_acc 0.156\n",
      "epoch 1, step 77: train_loss 3.890; train_acc 0.062\n",
      "epoch 1, step 78: train_loss 3.669; train_acc 0.094\n",
      "epoch 1, step 79: train_loss 3.258; train_acc 0.125\n",
      "epoch 1, step 80: train_loss 3.590; train_acc 0.062\n",
      "epoch 1, step 81: train_loss 3.389; train_acc 0.188\n",
      "epoch 1, step 82: train_loss 3.724; train_acc 0.062\n",
      "epoch 1, step 83: train_loss 3.741; train_acc 0.125\n",
      "epoch 1, step 84: train_loss 3.486; train_acc 0.094\n",
      "epoch 1, step 85: train_loss 3.298; train_acc 0.219\n",
      "epoch 1, step 86: train_loss 3.613; train_acc 0.156\n",
      "epoch 1, step 87: train_loss 3.564; train_acc 0.062\n",
      "epoch 1, step 88: train_loss 3.554; train_acc 0.094\n",
      "epoch 1, step 89: train_loss 3.330; train_acc 0.094\n",
      "epoch 1, step 90: train_loss 3.379; train_acc 0.188\n",
      "epoch 1, step 91: train_loss 3.885; train_acc 0.094\n",
      "epoch 1, step 92: train_loss 3.284; train_acc 0.125\n",
      "epoch 1, step 93: train_loss 3.608; train_acc 0.125\n",
      "epoch 1, step 94: train_loss 3.560; train_acc 0.156\n",
      "epoch 1, step 95: train_loss 3.771; train_acc 0.031\n",
      "epoch 1, step 96: train_loss 3.773; train_acc 0.125\n",
      "epoch 1, step 97: train_loss 3.283; train_acc 0.250\n",
      "epoch 1, step 98: train_loss 3.358; train_acc 0.156\n",
      "epoch 1, step 99: train_loss 3.456; train_acc 0.125\n",
      "epoch 1, step 100: train_loss 3.236; train_acc 0.156\n",
      "epoch 1, step 101: train_loss 3.715; train_acc 0.125\n",
      "epoch 1, step 102: train_loss 3.751; train_acc 0.000\n",
      "epoch 1, step 103: train_loss 3.454; train_acc 0.156\n",
      "epoch 1, step 104: train_loss 3.400; train_acc 0.219\n",
      "epoch 1, step 105: train_loss 3.715; train_acc 0.031\n",
      "epoch 1, step 106: train_loss 3.476; train_acc 0.188\n",
      "epoch 1, step 107: train_loss 3.139; train_acc 0.156\n",
      "epoch 1, step 108: train_loss 3.471; train_acc 0.219\n",
      "epoch 1, step 109: train_loss 3.418; train_acc 0.219\n",
      "epoch 1, step 110: train_loss 3.625; train_acc 0.125\n",
      "epoch 1, step 111: train_loss 3.625; train_acc 0.094\n",
      "epoch 1, step 112: train_loss 3.253; train_acc 0.219\n",
      "epoch 1, step 113: train_loss 3.687; train_acc 0.062\n",
      "epoch 1, step 114: train_loss 3.319; train_acc 0.094\n",
      "epoch 1, step 115: train_loss 3.336; train_acc 0.188\n",
      "epoch 1, step 116: train_loss 3.500; train_acc 0.156\n",
      "epoch 1, step 117: train_loss 3.089; train_acc 0.312\n",
      "epoch 1, step 118: train_loss 3.390; train_acc 0.156\n",
      "epoch 1, step 119: train_loss 3.439; train_acc 0.156\n",
      "epoch 1, step 120: train_loss 3.536; train_acc 0.000\n",
      "epoch 1, step 121: train_loss 3.624; train_acc 0.062\n",
      "epoch 1, step 122: train_loss 3.616; train_acc 0.094\n",
      "epoch 1, step 123: train_loss 3.367; train_acc 0.188\n",
      "epoch 1, step 124: train_loss 3.478; train_acc 0.156\n",
      "epoch 1, step 125: train_loss 3.281; train_acc 0.250\n",
      "epoch 1, step 126: train_loss 3.604; train_acc 0.094\n",
      "epoch 1, step 127: train_loss 3.389; train_acc 0.188\n",
      "epoch 1, step 128: train_loss 3.177; train_acc 0.219\n",
      "epoch 1, step 129: train_loss 3.601; train_acc 0.219\n",
      "epoch 1, step 130: train_loss 3.326; train_acc 0.250\n",
      "epoch 1, step 131: train_loss 3.862; train_acc 0.094\n",
      "epoch 1, step 132: train_loss 3.592; train_acc 0.125\n",
      "epoch 1, step 133: train_loss 3.563; train_acc 0.062\n",
      "epoch 1, step 134: train_loss 3.445; train_acc 0.156\n",
      "epoch 1, step 135: train_loss 3.833; train_acc 0.094\n",
      "epoch 1, step 136: train_loss 3.307; train_acc 0.062\n",
      "epoch 1, step 137: train_loss 3.471; train_acc 0.094\n",
      "epoch 1, step 138: train_loss 3.412; train_acc 0.156\n",
      "epoch 1, step 139: train_loss 3.508; train_acc 0.094\n",
      "epoch 1, step 140: train_loss 3.554; train_acc 0.125\n",
      "epoch 1, step 141: train_loss 3.245; train_acc 0.219\n",
      "epoch 1, step 142: train_loss 3.523; train_acc 0.094\n",
      "epoch 1, step 143: train_loss 3.568; train_acc 0.062\n",
      "epoch 1, step 144: train_loss 3.252; train_acc 0.156\n",
      "epoch 1, step 145: train_loss 3.330; train_acc 0.188\n",
      "epoch 1, step 146: train_loss 3.426; train_acc 0.062\n",
      "epoch 1, step 147: train_loss 3.493; train_acc 0.188\n",
      "epoch 1, step 148: train_loss 3.324; train_acc 0.188\n",
      "epoch 1, step 149: train_loss 3.480; train_acc 0.094\n",
      "epoch 1, step 150: train_loss 3.415; train_acc 0.094\n",
      "epoch 1, step 151: train_loss 3.636; train_acc 0.156\n",
      "epoch 1, step 152: train_loss 3.153; train_acc 0.219\n",
      "epoch 1, step 153: train_loss 3.411; train_acc 0.156\n",
      "epoch 1, step 154: train_loss 3.362; train_acc 0.219\n",
      "epoch 1, step 155: train_loss 3.877; train_acc 0.125\n",
      "epoch 1, step 156: train_loss 3.226; train_acc 0.125\n",
      "epoch 1, step 157: train_loss 2.999; train_acc 0.281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 158: train_loss 3.327; train_acc 0.125\n",
      "epoch 1, step 159: train_loss 3.403; train_acc 0.188\n",
      "epoch 1, step 160: train_loss 3.385; train_acc 0.125\n",
      "epoch 1, step 161: train_loss 3.797; train_acc 0.125\n",
      "epoch 1, step 162: train_loss 3.587; train_acc 0.156\n",
      "epoch 1, step 163: train_loss 3.414; train_acc 0.219\n",
      "epoch 1, step 164: train_loss 3.404; train_acc 0.188\n",
      "epoch 1, step 165: train_loss 3.242; train_acc 0.156\n",
      "epoch 1, step 166: train_loss 3.253; train_acc 0.219\n",
      "epoch 1, step 167: train_loss 3.079; train_acc 0.219\n",
      "epoch 1, step 168: train_loss 3.224; train_acc 0.188\n",
      "epoch 1, step 169: train_loss 3.438; train_acc 0.188\n",
      "epoch 1, step 170: train_loss 3.761; train_acc 0.156\n",
      "epoch 1, step 171: train_loss 3.366; train_acc 0.188\n",
      "epoch 1, step 172: train_loss 3.369; train_acc 0.156\n",
      "epoch 1, step 173: train_loss 3.309; train_acc 0.156\n",
      "epoch 1, step 174: train_loss 3.384; train_acc 0.188\n",
      "epoch 1, step 175: train_loss 3.310; train_acc 0.156\n",
      "epoch 1, step 176: train_loss 3.220; train_acc 0.188\n",
      "epoch 1, step 177: train_loss 3.277; train_acc 0.188\n",
      "epoch 1, step 178: train_loss 3.448; train_acc 0.125\n",
      "epoch 1, step 179: train_loss 3.202; train_acc 0.250\n",
      "epoch 1, step 180: train_loss 3.415; train_acc 0.188\n",
      "epoch 1, step 181: train_loss 3.458; train_acc 0.188\n",
      "epoch 1, step 182: train_loss 3.193; train_acc 0.219\n",
      "epoch 1, step 183: train_loss 3.782; train_acc 0.188\n",
      "epoch 1, step 184: train_loss 3.525; train_acc 0.125\n",
      "epoch 1, step 185: train_loss 3.365; train_acc 0.125\n",
      "epoch 1, step 186: train_loss 3.282; train_acc 0.188\n",
      "epoch 1, step 187: train_loss 3.252; train_acc 0.188\n",
      "epoch 1, step 188: train_loss 3.056; train_acc 0.250\n",
      "epoch 1, step 189: train_loss 3.211; train_acc 0.219\n",
      "epoch 1, step 190: train_loss 3.526; train_acc 0.156\n",
      "epoch 1, step 191: train_loss 3.089; train_acc 0.188\n",
      "epoch 1, step 192: train_loss 3.141; train_acc 0.250\n",
      "epoch 1, step 193: train_loss 3.117; train_acc 0.156\n",
      "epoch 1, step 194: train_loss 3.319; train_acc 0.188\n",
      "epoch 1, step 195: train_loss 3.239; train_acc 0.281\n",
      "epoch 1, step 196: train_loss 3.362; train_acc 0.156\n",
      "epoch 1, step 197: train_loss 3.379; train_acc 0.188\n",
      "epoch 1, step 198: train_loss 3.025; train_acc 0.250\n",
      "epoch 1, step 199: train_loss 3.152; train_acc 0.219\n",
      "epoch 1, step 200: train_loss 3.273; train_acc 0.188\n",
      "epoch 1, step 201: train_loss 2.985; train_acc 0.188\n",
      "epoch 1, step 202: train_loss 3.400; train_acc 0.219\n",
      "epoch 1, step 203: train_loss 3.531; train_acc 0.156\n",
      "epoch 1, step 204: train_loss 3.099; train_acc 0.281\n",
      "epoch 1, step 205: train_loss 3.358; train_acc 0.188\n",
      "epoch 1, step 206: train_loss 3.325; train_acc 0.188\n",
      "epoch 1, step 207: train_loss 3.132; train_acc 0.250\n",
      "epoch 1, step 208: train_loss 3.211; train_acc 0.219\n",
      "epoch 1, step 209: train_loss 3.152; train_acc 0.375\n",
      "epoch 1, step 210: train_loss 3.290; train_acc 0.188\n",
      "epoch 1, step 211: train_loss 3.156; train_acc 0.281\n",
      "epoch 1, step 212: train_loss 3.412; train_acc 0.156\n",
      "epoch 1, step 213: train_loss 3.459; train_acc 0.156\n",
      "epoch 1, step 214: train_loss 3.666; train_acc 0.062\n",
      "epoch 1, step 215: train_loss 3.384; train_acc 0.219\n",
      "epoch 1, step 216: train_loss 3.131; train_acc 0.188\n",
      "epoch 1, step 217: train_loss 3.064; train_acc 0.281\n",
      "epoch 1, step 218: train_loss 2.933; train_acc 0.250\n",
      "epoch 1, step 219: train_loss 3.054; train_acc 0.219\n",
      "epoch 1, step 220: train_loss 3.444; train_acc 0.188\n",
      "epoch 1, step 221: train_loss 3.529; train_acc 0.094\n",
      "epoch 1, step 222: train_loss 3.356; train_acc 0.125\n",
      "epoch 1, step 223: train_loss 3.172; train_acc 0.188\n",
      "epoch 1, step 224: train_loss 3.161; train_acc 0.156\n",
      "epoch 1, step 225: train_loss 3.257; train_acc 0.188\n",
      "epoch 1, step 226: train_loss 3.734; train_acc 0.125\n",
      "epoch 1, step 227: train_loss 2.669; train_acc 0.375\n",
      "epoch 1, step 228: train_loss 3.094; train_acc 0.188\n",
      "epoch 1, step 229: train_loss 3.050; train_acc 0.250\n",
      "epoch 1, step 230: train_loss 3.461; train_acc 0.062\n",
      "epoch 1, step 231: train_loss 3.174; train_acc 0.156\n",
      "epoch 1, step 232: train_loss 3.169; train_acc 0.250\n",
      "epoch 1, step 233: train_loss 3.087; train_acc 0.250\n",
      "epoch 1, step 234: train_loss 3.696; train_acc 0.094\n",
      "epoch 1, step 235: train_loss 3.199; train_acc 0.250\n",
      "epoch 1, step 236: train_loss 3.162; train_acc 0.156\n",
      "epoch 1, step 237: train_loss 3.478; train_acc 0.188\n",
      "epoch 1, step 238: train_loss 3.456; train_acc 0.094\n",
      "epoch 1, step 239: train_loss 3.345; train_acc 0.188\n",
      "epoch 1, step 240: train_loss 3.775; train_acc 0.094\n",
      "epoch 1, step 241: train_loss 3.398; train_acc 0.188\n",
      "epoch 1, step 242: train_loss 3.262; train_acc 0.156\n",
      "epoch 1, step 243: train_loss 3.475; train_acc 0.094\n",
      "epoch 1, step 244: train_loss 3.306; train_acc 0.125\n",
      "epoch 1, step 245: train_loss 2.977; train_acc 0.219\n",
      "epoch 1, step 246: train_loss 3.242; train_acc 0.156\n",
      "epoch 1, step 247: train_loss 3.312; train_acc 0.219\n",
      "epoch 1, step 248: train_loss 3.239; train_acc 0.125\n",
      "epoch 1, step 249: train_loss 3.205; train_acc 0.156\n",
      "epoch 1, step 250: train_loss 3.200; train_acc 0.219\n",
      "epoch 1, step 251: train_loss 3.000; train_acc 0.250\n",
      "epoch 1, step 252: train_loss 2.821; train_acc 0.312\n",
      "epoch 1, step 253: train_loss 2.856; train_acc 0.250\n",
      "epoch 1, step 254: train_loss 3.065; train_acc 0.250\n",
      "epoch 1, step 255: train_loss 3.636; train_acc 0.156\n",
      "epoch 1, step 256: train_loss 3.092; train_acc 0.219\n",
      "epoch 1, step 257: train_loss 3.069; train_acc 0.125\n",
      "epoch 1, step 258: train_loss 3.274; train_acc 0.188\n",
      "epoch 1, step 259: train_loss 3.211; train_acc 0.156\n",
      "epoch 1, step 260: train_loss 3.139; train_acc 0.156\n",
      "epoch 1, step 261: train_loss 2.628; train_acc 0.312\n",
      "epoch 1, step 262: train_loss 3.254; train_acc 0.219\n",
      "epoch 1, step 263: train_loss 3.273; train_acc 0.188\n",
      "epoch 1, step 264: train_loss 3.316; train_acc 0.156\n",
      "epoch 1, step 265: train_loss 3.732; train_acc 0.094\n",
      "epoch 1, step 266: train_loss 3.390; train_acc 0.219\n",
      "epoch 1, step 267: train_loss 2.988; train_acc 0.156\n",
      "epoch 1, step 268: train_loss 3.353; train_acc 0.094\n",
      "epoch 1, step 269: train_loss 2.951; train_acc 0.250\n",
      "epoch 1, step 270: train_loss 3.596; train_acc 0.094\n",
      "epoch 1, step 271: train_loss 3.424; train_acc 0.188\n",
      "epoch 1, step 272: train_loss 3.482; train_acc 0.094\n",
      "epoch 1, step 273: train_loss 3.076; train_acc 0.219\n",
      "epoch 1, step 274: train_loss 3.004; train_acc 0.250\n",
      "epoch 1, step 275: train_loss 3.472; train_acc 0.188\n",
      "epoch 1, step 276: train_loss 3.237; train_acc 0.250\n",
      "epoch 1, step 277: train_loss 3.140; train_acc 0.219\n",
      "epoch 1, step 278: train_loss 2.884; train_acc 0.281\n",
      "epoch 1, step 279: train_loss 3.141; train_acc 0.188\n",
      "epoch 1, step 280: train_loss 3.243; train_acc 0.188\n",
      "epoch 1, step 281: train_loss 2.937; train_acc 0.156\n",
      "epoch 1, step 282: train_loss 3.189; train_acc 0.219\n",
      "epoch 1, step 283: train_loss 3.412; train_acc 0.125\n",
      "epoch 1, step 284: train_loss 3.346; train_acc 0.156\n",
      "epoch 1, step 285: train_loss 3.347; train_acc 0.188\n",
      "epoch 1, step 286: train_loss 2.466; train_acc 0.469\n",
      "epoch 1, step 287: train_loss 3.291; train_acc 0.188\n",
      "epoch 1, step 288: train_loss 2.988; train_acc 0.250\n",
      "epoch 1, step 289: train_loss 3.230; train_acc 0.281\n",
      "epoch 1, step 290: train_loss 3.174; train_acc 0.188\n",
      "epoch 1, step 291: train_loss 3.277; train_acc 0.125\n",
      "epoch 1, step 292: train_loss 3.284; train_acc 0.188\n",
      "epoch 1, step 293: train_loss 2.576; train_acc 0.344\n",
      "epoch 1, step 294: train_loss 3.620; train_acc 0.125\n",
      "epoch 1, step 295: train_loss 2.973; train_acc 0.250\n",
      "epoch 1, step 296: train_loss 3.219; train_acc 0.188\n",
      "epoch 1, step 297: train_loss 3.575; train_acc 0.031\n",
      "epoch 1, step 298: train_loss 2.780; train_acc 0.312\n",
      "epoch 1, step 299: train_loss 3.101; train_acc 0.125\n",
      "epoch 1, step 300: train_loss 3.230; train_acc 0.156\n",
      "epoch 1, step 301: train_loss 2.782; train_acc 0.344\n",
      "epoch 1, step 302: train_loss 2.718; train_acc 0.219\n",
      "epoch 1, step 303: train_loss 3.458; train_acc 0.281\n",
      "epoch 1, step 304: train_loss 3.653; train_acc 0.094\n",
      "epoch 1, step 305: train_loss 3.059; train_acc 0.312\n",
      "epoch 1, step 306: train_loss 3.293; train_acc 0.219\n",
      "epoch 1, step 307: train_loss 3.315; train_acc 0.188\n",
      "epoch 1, step 308: train_loss 3.278; train_acc 0.188\n",
      "epoch 1, step 309: train_loss 3.406; train_acc 0.156\n",
      "epoch 1, step 310: train_loss 3.209; train_acc 0.281\n",
      "epoch 1, step 311: train_loss 2.898; train_acc 0.281\n",
      "epoch 1, step 312: train_loss 3.715; train_acc 0.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 313: train_loss 3.276; train_acc 0.281\n",
      "epoch 1, step 314: train_loss 3.573; train_acc 0.094\n",
      "epoch 1, step 315: train_loss 2.807; train_acc 0.312\n",
      "epoch 1, step 316: train_loss 3.582; train_acc 0.125\n",
      "epoch 1, step 317: train_loss 3.282; train_acc 0.250\n",
      "epoch 1, step 318: train_loss 3.237; train_acc 0.219\n",
      "epoch 1, step 319: train_loss 2.993; train_acc 0.281\n",
      "epoch 1, step 320: train_loss 3.306; train_acc 0.156\n",
      "epoch 1, step 321: train_loss 2.941; train_acc 0.250\n",
      "epoch 1, step 322: train_loss 3.266; train_acc 0.219\n",
      "epoch 1, step 323: train_loss 3.256; train_acc 0.156\n",
      "epoch 1, step 324: train_loss 2.795; train_acc 0.250\n",
      "epoch 1, step 325: train_loss 3.216; train_acc 0.219\n",
      "epoch 1, step 326: train_loss 2.682; train_acc 0.312\n",
      "epoch 1, step 327: train_loss 3.571; train_acc 0.156\n",
      "epoch 1, step 328: train_loss 3.120; train_acc 0.219\n",
      "epoch 1, step 329: train_loss 2.749; train_acc 0.375\n",
      "epoch 1, step 330: train_loss 3.626; train_acc 0.156\n",
      "epoch 1, step 331: train_loss 2.817; train_acc 0.281\n",
      "epoch 1, step 332: train_loss 3.110; train_acc 0.188\n",
      "epoch 1, step 333: train_loss 2.917; train_acc 0.250\n",
      "epoch 1, step 334: train_loss 2.728; train_acc 0.344\n",
      "epoch 1, step 335: train_loss 3.127; train_acc 0.188\n",
      "epoch 1, step 336: train_loss 3.176; train_acc 0.281\n",
      "epoch 1, step 337: train_loss 3.234; train_acc 0.219\n",
      "epoch 1, step 338: train_loss 3.524; train_acc 0.125\n",
      "epoch 1, step 339: train_loss 3.227; train_acc 0.156\n",
      "epoch 1, step 340: train_loss 2.837; train_acc 0.188\n",
      "epoch 1, step 341: train_loss 3.254; train_acc 0.219\n",
      "epoch 1, step 342: train_loss 2.780; train_acc 0.312\n",
      "epoch 1, step 343: train_loss 3.382; train_acc 0.125\n",
      "epoch 1, step 344: train_loss 3.382; train_acc 0.188\n",
      "epoch 1, step 345: train_loss 2.846; train_acc 0.219\n",
      "epoch 1, step 346: train_loss 3.311; train_acc 0.219\n",
      "epoch 1, step 347: train_loss 3.100; train_acc 0.188\n",
      "epoch 1, step 348: train_loss 2.617; train_acc 0.375\n",
      "epoch 1, step 349: train_loss 3.186; train_acc 0.188\n",
      "epoch 1, step 350: train_loss 2.815; train_acc 0.375\n",
      "epoch 1, step 351: train_loss 3.566; train_acc 0.062\n",
      "epoch 1, step 352: train_loss 3.273; train_acc 0.125\n",
      "epoch 1, step 353: train_loss 3.205; train_acc 0.125\n",
      "epoch 1, step 354: train_loss 3.265; train_acc 0.094\n",
      "epoch 1, step 355: train_loss 3.630; train_acc 0.062\n",
      "epoch 1, step 356: train_loss 2.827; train_acc 0.281\n",
      "epoch 1, step 357: train_loss 3.284; train_acc 0.188\n",
      "epoch 1, step 358: train_loss 3.093; train_acc 0.188\n",
      "epoch 1, step 359: train_loss 3.517; train_acc 0.156\n",
      "epoch 1, step 360: train_loss 3.116; train_acc 0.219\n",
      "epoch 1, step 361: train_loss 3.339; train_acc 0.156\n",
      "epoch 1, step 362: train_loss 2.626; train_acc 0.281\n",
      "epoch 1, step 363: train_loss 3.148; train_acc 0.250\n",
      "epoch 1, step 364: train_loss 2.754; train_acc 0.281\n",
      "epoch 1, step 365: train_loss 2.775; train_acc 0.312\n",
      "epoch 1, step 366: train_loss 3.018; train_acc 0.250\n",
      "epoch 1, step 367: train_loss 3.117; train_acc 0.188\n",
      "epoch 1, step 368: train_loss 3.075; train_acc 0.125\n",
      "epoch 1, step 369: train_loss 3.145; train_acc 0.156\n",
      "epoch 1, step 370: train_loss 3.467; train_acc 0.281\n",
      "epoch 1, step 371: train_loss 2.904; train_acc 0.156\n",
      "epoch 1, step 372: train_loss 2.953; train_acc 0.375\n",
      "epoch 1, step 373: train_loss 3.237; train_acc 0.125\n",
      "epoch 1, step 374: train_loss 3.081; train_acc 0.219\n",
      "epoch 1, step 375: train_loss 2.773; train_acc 0.344\n",
      "epoch 1, step 376: train_loss 2.952; train_acc 0.188\n",
      "epoch 1, step 377: train_loss 3.611; train_acc 0.188\n",
      "epoch 1, step 378: train_loss 2.933; train_acc 0.156\n",
      "epoch 1, step 379: train_loss 3.136; train_acc 0.219\n",
      "epoch 1, step 380: train_loss 3.536; train_acc 0.125\n",
      "epoch 1, step 381: train_loss 2.647; train_acc 0.250\n",
      "epoch 1, step 382: train_loss 2.927; train_acc 0.219\n",
      "epoch 1, step 383: train_loss 3.359; train_acc 0.188\n",
      "epoch 1, step 384: train_loss 3.087; train_acc 0.250\n",
      "epoch 1, step 385: train_loss 2.821; train_acc 0.312\n",
      "epoch 1, step 386: train_loss 3.023; train_acc 0.375\n",
      "epoch 1, step 387: train_loss 3.387; train_acc 0.188\n",
      "epoch 1, step 388: train_loss 2.762; train_acc 0.406\n",
      "epoch 1, step 389: train_loss 3.105; train_acc 0.219\n",
      "epoch 1, step 390: train_loss 2.881; train_acc 0.281\n",
      "epoch 1, step 391: train_loss 2.939; train_acc 0.281\n",
      "epoch 1, step 392: train_loss 3.222; train_acc 0.219\n",
      "epoch 1, step 393: train_loss 3.423; train_acc 0.125\n",
      "epoch 1, step 394: train_loss 2.690; train_acc 0.219\n",
      "epoch 1, step 395: train_loss 3.302; train_acc 0.250\n",
      "epoch 1, step 396: train_loss 3.442; train_acc 0.094\n",
      "epoch 1, step 397: train_loss 3.137; train_acc 0.219\n",
      "epoch 1, step 398: train_loss 2.947; train_acc 0.219\n",
      "epoch 1, step 399: train_loss 2.753; train_acc 0.281\n",
      "epoch 1, step 400: train_loss 3.053; train_acc 0.312\n",
      "epoch 1, step 401: train_loss 3.153; train_acc 0.344\n",
      "epoch 1, step 402: train_loss 3.077; train_acc 0.188\n",
      "epoch 1, step 403: train_loss 3.135; train_acc 0.250\n",
      "epoch 1, step 404: train_loss 3.151; train_acc 0.188\n",
      "epoch 1, step 405: train_loss 3.079; train_acc 0.250\n",
      "epoch 1, step 406: train_loss 3.590; train_acc 0.156\n",
      "epoch 1, step 407: train_loss 3.152; train_acc 0.188\n",
      "epoch 1, step 408: train_loss 2.946; train_acc 0.312\n",
      "epoch 1, step 409: train_loss 2.862; train_acc 0.312\n",
      "epoch 1, step 410: train_loss 3.386; train_acc 0.125\n",
      "epoch 1, step 411: train_loss 3.197; train_acc 0.312\n",
      "epoch 1, step 412: train_loss 2.741; train_acc 0.281\n",
      "epoch 1, step 413: train_loss 2.775; train_acc 0.188\n",
      "epoch 1, step 414: train_loss 3.192; train_acc 0.188\n",
      "epoch 1, step 415: train_loss 3.041; train_acc 0.281\n",
      "epoch 1, step 416: train_loss 3.048; train_acc 0.281\n",
      "epoch 1, step 417: train_loss 2.798; train_acc 0.312\n",
      "epoch 1, step 418: train_loss 3.105; train_acc 0.250\n",
      "epoch 1, step 419: train_loss 2.808; train_acc 0.406\n",
      "epoch 1, step 420: train_loss 3.335; train_acc 0.125\n",
      "epoch 1, step 421: train_loss 2.811; train_acc 0.344\n",
      "epoch 1, step 422: train_loss 3.072; train_acc 0.250\n",
      "epoch 1, step 423: train_loss 3.030; train_acc 0.344\n",
      "epoch 1, step 424: train_loss 2.925; train_acc 0.312\n",
      "epoch 1, step 425: train_loss 2.656; train_acc 0.375\n",
      "epoch 1, step 426: train_loss 3.219; train_acc 0.188\n",
      "epoch 1, step 427: train_loss 3.117; train_acc 0.219\n",
      "epoch 1, step 428: train_loss 3.305; train_acc 0.219\n",
      "epoch 1, step 429: train_loss 3.588; train_acc 0.125\n",
      "epoch 1, step 430: train_loss 2.620; train_acc 0.312\n",
      "epoch 1, step 431: train_loss 3.322; train_acc 0.156\n",
      "epoch 1, step 432: train_loss 3.167; train_acc 0.156\n",
      "epoch 1, step 433: train_loss 2.730; train_acc 0.250\n",
      "epoch 1, step 434: train_loss 3.196; train_acc 0.156\n",
      "epoch 1, step 435: train_loss 2.717; train_acc 0.406\n",
      "epoch 1, step 436: train_loss 2.940; train_acc 0.281\n",
      "epoch 1, step 437: train_loss 3.040; train_acc 0.219\n",
      "epoch 1, step 438: train_loss 2.843; train_acc 0.312\n",
      "epoch 1, step 439: train_loss 3.226; train_acc 0.219\n",
      "epoch 1, step 440: train_loss 3.429; train_acc 0.219\n",
      "epoch 1, step 441: train_loss 3.571; train_acc 0.188\n",
      "epoch 1, step 442: train_loss 3.188; train_acc 0.281\n",
      "epoch 1, step 443: train_loss 3.817; train_acc 0.062\n",
      "epoch 1, step 444: train_loss 3.466; train_acc 0.188\n",
      "epoch 1, step 445: train_loss 2.844; train_acc 0.188\n",
      "epoch 1, step 446: train_loss 2.928; train_acc 0.125\n",
      "epoch 1, step 447: train_loss 3.130; train_acc 0.281\n",
      "epoch 1, step 448: train_loss 2.643; train_acc 0.312\n",
      "epoch 1, step 449: train_loss 3.192; train_acc 0.281\n",
      "epoch 1, step 450: train_loss 3.229; train_acc 0.281\n",
      "epoch 1, step 451: train_loss 3.700; train_acc 0.094\n",
      "epoch 1, step 452: train_loss 2.940; train_acc 0.344\n",
      "epoch 1, step 453: train_loss 3.412; train_acc 0.125\n",
      "epoch 1, step 454: train_loss 3.002; train_acc 0.281\n",
      "epoch 1, step 455: train_loss 2.834; train_acc 0.344\n",
      "epoch 1, step 456: train_loss 3.136; train_acc 0.219\n",
      "epoch 1, step 457: train_loss 2.887; train_acc 0.156\n",
      "epoch 1, step 458: train_loss 3.025; train_acc 0.250\n",
      "epoch 1, step 459: train_loss 3.519; train_acc 0.188\n",
      "epoch 1, step 460: train_loss 2.918; train_acc 0.156\n",
      "epoch 1, step 461: train_loss 3.418; train_acc 0.125\n",
      "epoch 1, step 462: train_loss 3.075; train_acc 0.188\n",
      "epoch 1, step 463: train_loss 3.022; train_acc 0.312\n",
      "epoch 1, step 464: train_loss 3.300; train_acc 0.125\n",
      "epoch 1, step 465: train_loss 3.323; train_acc 0.094\n",
      "epoch 1, step 466: train_loss 2.755; train_acc 0.219\n",
      "epoch 1, step 467: train_loss 3.079; train_acc 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 468: train_loss 3.036; train_acc 0.312\n",
      "epoch 1, step 469: train_loss 3.177; train_acc 0.188\n",
      "epoch 1, step 470: train_loss 2.869; train_acc 0.188\n",
      "epoch 1, step 471: train_loss 2.943; train_acc 0.250\n",
      "epoch 1, step 472: train_loss 3.058; train_acc 0.250\n",
      "epoch 1, step 473: train_loss 2.820; train_acc 0.219\n",
      "epoch 1, step 474: train_loss 3.490; train_acc 0.219\n",
      "epoch 1, step 475: train_loss 3.096; train_acc 0.219\n",
      "epoch 1, step 476: train_loss 2.876; train_acc 0.344\n",
      "epoch 1, step 477: train_loss 3.009; train_acc 0.188\n",
      "epoch 1, step 478: train_loss 2.901; train_acc 0.250\n",
      "epoch 1, step 479: train_loss 3.547; train_acc 0.125\n",
      "epoch 1, step 480: train_loss 3.001; train_acc 0.250\n",
      "epoch 1, step 481: train_loss 2.914; train_acc 0.281\n",
      "epoch 1, step 482: train_loss 3.259; train_acc 0.250\n",
      "epoch 1, step 483: train_loss 3.200; train_acc 0.281\n",
      "epoch 1, step 484: train_loss 3.327; train_acc 0.281\n",
      "epoch 1, step 485: train_loss 3.055; train_acc 0.281\n",
      "epoch 1, step 486: train_loss 2.544; train_acc 0.312\n",
      "epoch 1, step 487: train_loss 2.692; train_acc 0.312\n",
      "epoch 1, step 488: train_loss 2.650; train_acc 0.312\n",
      "epoch 1, step 489: train_loss 3.495; train_acc 0.219\n",
      "epoch 1, step 490: train_loss 2.640; train_acc 0.344\n",
      "epoch 1, step 491: train_loss 3.072; train_acc 0.250\n",
      "epoch 1, step 492: train_loss 2.620; train_acc 0.281\n",
      "epoch 1, step 493: train_loss 2.699; train_acc 0.344\n",
      "epoch 1, step 494: train_loss 2.707; train_acc 0.250\n",
      "epoch 1, step 495: train_loss 3.366; train_acc 0.125\n",
      "epoch 1, step 496: train_loss 2.423; train_acc 0.281\n",
      "epoch 1, step 497: train_loss 3.407; train_acc 0.188\n",
      "epoch 1, step 498: train_loss 2.676; train_acc 0.312\n",
      "epoch 1, step 499: train_loss 2.818; train_acc 0.312\n",
      "epoch 1, step 500: train_loss 2.618; train_acc 0.281\n",
      "epoch 1, step 501: train_loss 3.186; train_acc 0.250\n",
      "epoch 1, step 502: train_loss 3.159; train_acc 0.219\n",
      "epoch 1, step 503: train_loss 3.176; train_acc 0.250\n",
      "epoch 1, step 504: train_loss 2.918; train_acc 0.188\n",
      "epoch 1, step 505: train_loss 2.772; train_acc 0.250\n",
      "epoch 1, step 506: train_loss 3.205; train_acc 0.219\n",
      "epoch 1, step 507: train_loss 3.018; train_acc 0.312\n",
      "epoch 1, step 508: train_loss 3.170; train_acc 0.156\n",
      "epoch 1, step 509: train_loss 3.297; train_acc 0.250\n",
      "epoch 1, step 510: train_loss 2.986; train_acc 0.281\n",
      "epoch 1, step 511: train_loss 3.775; train_acc 0.094\n",
      "epoch 1, step 512: train_loss 3.276; train_acc 0.125\n",
      "epoch 1, step 513: train_loss 3.439; train_acc 0.094\n",
      "epoch 1, step 514: train_loss 3.299; train_acc 0.156\n",
      "epoch 1, step 515: train_loss 2.829; train_acc 0.219\n",
      "epoch 1, step 516: train_loss 3.072; train_acc 0.312\n",
      "epoch 1, step 517: train_loss 3.093; train_acc 0.156\n",
      "epoch 1, step 518: train_loss 3.262; train_acc 0.156\n",
      "epoch 1, step 519: train_loss 3.266; train_acc 0.188\n",
      "epoch 1, step 520: train_loss 2.850; train_acc 0.281\n",
      "epoch 1, step 521: train_loss 3.215; train_acc 0.250\n",
      "epoch 1, step 522: train_loss 2.879; train_acc 0.188\n",
      "epoch 1, step 523: train_loss 2.937; train_acc 0.281\n",
      "epoch 1, step 524: train_loss 2.343; train_acc 0.438\n",
      "epoch 1, step 525: train_loss 2.669; train_acc 0.281\n",
      "epoch 1, step 526: train_loss 3.565; train_acc 0.156\n",
      "epoch 1, step 527: train_loss 3.037; train_acc 0.250\n",
      "epoch 1, step 528: train_loss 3.305; train_acc 0.219\n",
      "epoch 1, step 529: train_loss 2.743; train_acc 0.344\n",
      "epoch 1, step 530: train_loss 3.326; train_acc 0.281\n",
      "epoch 1, step 531: train_loss 3.304; train_acc 0.188\n",
      "epoch 1, step 532: train_loss 3.004; train_acc 0.188\n",
      "epoch 1, step 533: train_loss 3.001; train_acc 0.250\n",
      "epoch 1, step 534: train_loss 2.943; train_acc 0.344\n",
      "epoch 1, step 535: train_loss 3.077; train_acc 0.344\n",
      "epoch 1, step 536: train_loss 3.012; train_acc 0.250\n",
      "epoch 1, step 537: train_loss 2.907; train_acc 0.219\n",
      "epoch 1, step 538: train_loss 2.982; train_acc 0.188\n",
      "epoch 1, step 539: train_loss 2.945; train_acc 0.281\n",
      "epoch 1, step 540: train_loss 2.701; train_acc 0.281\n",
      "epoch 1, step 541: train_loss 3.370; train_acc 0.219\n",
      "epoch 1, step 542: train_loss 3.187; train_acc 0.281\n",
      "epoch 1, step 543: train_loss 3.260; train_acc 0.250\n",
      "epoch 1, step 544: train_loss 2.820; train_acc 0.250\n",
      "epoch 1, step 545: train_loss 2.668; train_acc 0.250\n",
      "epoch 1, step 546: train_loss 3.095; train_acc 0.156\n",
      "epoch 1, step 547: train_loss 2.676; train_acc 0.250\n",
      "epoch 1, step 548: train_loss 3.101; train_acc 0.250\n",
      "epoch 1, step 549: train_loss 2.945; train_acc 0.219\n",
      "epoch 1, step 550: train_loss 2.977; train_acc 0.281\n",
      "epoch 1, step 551: train_loss 2.945; train_acc 0.219\n",
      "epoch 1, step 552: train_loss 2.926; train_acc 0.281\n",
      "epoch 1, step 553: train_loss 3.153; train_acc 0.188\n",
      "epoch 1, step 554: train_loss 3.075; train_acc 0.188\n",
      "epoch 1, step 555: train_loss 3.181; train_acc 0.156\n",
      "epoch 1, step 556: train_loss 2.914; train_acc 0.312\n",
      "epoch 1, step 557: train_loss 3.037; train_acc 0.188\n",
      "epoch 1, step 558: train_loss 3.154; train_acc 0.156\n",
      "epoch 1, step 559: train_loss 2.689; train_acc 0.281\n",
      "epoch 1, step 560: train_loss 3.158; train_acc 0.156\n",
      "epoch 1, step 561: train_loss 2.519; train_acc 0.406\n",
      "epoch 1, step 562: train_loss 2.922; train_acc 0.250\n",
      "epoch 1, step 563: train_loss 3.121; train_acc 0.250\n",
      "epoch 1, step 564: train_loss 2.830; train_acc 0.219\n",
      "epoch 1, step 565: train_loss 2.883; train_acc 0.219\n",
      "epoch 1, step 566: train_loss 2.485; train_acc 0.406\n",
      "epoch 1, step 567: train_loss 2.830; train_acc 0.312\n",
      "epoch 1, step 568: train_loss 2.403; train_acc 0.344\n",
      "epoch 1, step 569: train_loss 2.352; train_acc 0.406\n",
      "epoch 1, step 570: train_loss 3.592; train_acc 0.031\n",
      "epoch 1, step 571: train_loss 2.941; train_acc 0.281\n",
      "epoch 1, step 572: train_loss 3.023; train_acc 0.312\n",
      "epoch 1, step 573: train_loss 2.199; train_acc 0.469\n",
      "epoch 1, step 574: train_loss 3.083; train_acc 0.281\n",
      "epoch 1, step 575: train_loss 2.795; train_acc 0.281\n",
      "epoch 1, step 576: train_loss 2.721; train_acc 0.375\n",
      "epoch 1, step 577: train_loss 2.690; train_acc 0.281\n",
      "epoch 1, step 578: train_loss 2.974; train_acc 0.156\n",
      "epoch 1, step 579: train_loss 3.459; train_acc 0.188\n",
      "epoch 1, step 580: train_loss 2.927; train_acc 0.344\n",
      "epoch 1, step 581: train_loss 3.552; train_acc 0.156\n",
      "epoch 1, step 582: train_loss 3.233; train_acc 0.219\n",
      "epoch 1, step 583: train_loss 3.031; train_acc 0.219\n",
      "epoch 1, step 584: train_loss 2.791; train_acc 0.281\n",
      "epoch 1, step 585: train_loss 2.746; train_acc 0.281\n",
      "epoch 1, step 586: train_loss 2.930; train_acc 0.250\n",
      "epoch 1, step 587: train_loss 3.106; train_acc 0.188\n",
      "epoch 1, step 588: train_loss 2.838; train_acc 0.250\n",
      "epoch 1, step 589: train_loss 2.935; train_acc 0.281\n",
      "epoch 1, step 590: train_loss 2.996; train_acc 0.219\n",
      "epoch 1, step 591: train_loss 2.924; train_acc 0.156\n",
      "epoch 1, step 592: train_loss 3.172; train_acc 0.219\n",
      "epoch 1, step 593: train_loss 2.485; train_acc 0.344\n",
      "epoch 1, step 594: train_loss 2.755; train_acc 0.344\n",
      "epoch 1, step 595: train_loss 2.790; train_acc 0.250\n",
      "epoch 1, step 596: train_loss 2.587; train_acc 0.344\n",
      "epoch 1, step 597: train_loss 2.649; train_acc 0.250\n",
      "epoch 1, step 598: train_loss 2.853; train_acc 0.312\n",
      "epoch 1, step 599: train_loss 3.277; train_acc 0.219\n",
      "epoch 1, step 600: train_loss 2.733; train_acc 0.312\n",
      "epoch 1, step 601: train_loss 3.226; train_acc 0.219\n",
      "epoch 1, step 602: train_loss 2.811; train_acc 0.281\n",
      "epoch 1, step 603: train_loss 3.055; train_acc 0.250\n",
      "epoch 1, step 604: train_loss 2.720; train_acc 0.312\n",
      "epoch 1, step 605: train_loss 2.687; train_acc 0.406\n",
      "epoch 1, step 606: train_loss 3.160; train_acc 0.250\n",
      "epoch 1, step 607: train_loss 2.819; train_acc 0.312\n",
      "epoch 1, step 608: train_loss 2.556; train_acc 0.375\n",
      "epoch 1, step 609: train_loss 2.724; train_acc 0.344\n",
      "epoch 1, step 610: train_loss 3.027; train_acc 0.250\n",
      "epoch 1, step 611: train_loss 3.368; train_acc 0.250\n",
      "epoch 1, step 612: train_loss 3.091; train_acc 0.219\n",
      "epoch 1, step 613: train_loss 2.671; train_acc 0.281\n",
      "epoch 1, step 614: train_loss 3.529; train_acc 0.219\n",
      "epoch 1, step 615: train_loss 2.985; train_acc 0.312\n",
      "epoch 1, step 616: train_loss 2.552; train_acc 0.406\n",
      "epoch 1, step 617: train_loss 2.785; train_acc 0.375\n",
      "epoch 1, step 618: train_loss 2.716; train_acc 0.375\n",
      "epoch 1, step 619: train_loss 2.868; train_acc 0.250\n",
      "epoch 1, step 620: train_loss 2.770; train_acc 0.250\n",
      "epoch 1, step 621: train_loss 3.027; train_acc 0.219\n",
      "epoch 1, step 622: train_loss 3.071; train_acc 0.219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 623: train_loss 2.874; train_acc 0.281\n",
      "epoch 1, step 624: train_loss 2.669; train_acc 0.375\n",
      "epoch 1, step 625: train_loss 3.011; train_acc 0.219\n",
      "epoch 1, step 626: train_loss 2.801; train_acc 0.219\n",
      "epoch 1, step 627: train_loss 2.377; train_acc 0.438\n",
      "epoch 1, step 628: train_loss 2.826; train_acc 0.281\n",
      "epoch 1, step 629: train_loss 2.364; train_acc 0.406\n",
      "epoch 1, step 630: train_loss 2.642; train_acc 0.375\n",
      "epoch 1, step 631: train_loss 3.147; train_acc 0.062\n",
      "epoch 1, step 632: train_loss 2.813; train_acc 0.375\n",
      "epoch 1, step 633: train_loss 2.953; train_acc 0.250\n",
      "epoch 1, step 634: train_loss 3.187; train_acc 0.312\n",
      "epoch 1, step 635: train_loss 2.356; train_acc 0.375\n",
      "epoch 1, step 636: train_loss 3.248; train_acc 0.250\n",
      "epoch 1, step 637: train_loss 2.477; train_acc 0.438\n",
      "epoch 1, step 638: train_loss 2.582; train_acc 0.344\n",
      "epoch 1, step 639: train_loss 2.629; train_acc 0.375\n",
      "epoch 1, step 640: train_loss 2.599; train_acc 0.312\n",
      "epoch 1, step 641: train_loss 3.530; train_acc 0.188\n",
      "epoch 1, step 642: train_loss 2.350; train_acc 0.438\n",
      "epoch 1, step 643: train_loss 3.432; train_acc 0.188\n",
      "epoch 1, step 644: train_loss 3.196; train_acc 0.219\n",
      "epoch 1, step 645: train_loss 2.229; train_acc 0.438\n",
      "epoch 1, step 646: train_loss 3.145; train_acc 0.219\n",
      "epoch 1, step 647: train_loss 3.519; train_acc 0.250\n",
      "epoch 1, step 648: train_loss 3.436; train_acc 0.219\n",
      "epoch 1, step 649: train_loss 3.040; train_acc 0.219\n",
      "epoch 1, step 650: train_loss 3.101; train_acc 0.250\n",
      "epoch 1, step 651: train_loss 2.946; train_acc 0.312\n",
      "epoch 1, step 652: train_loss 2.853; train_acc 0.250\n",
      "epoch 1, step 653: train_loss 2.753; train_acc 0.250\n",
      "epoch 1, step 654: train_loss 2.885; train_acc 0.219\n",
      "epoch 1, step 655: train_loss 2.900; train_acc 0.312\n",
      "epoch 1, step 656: train_loss 3.030; train_acc 0.219\n",
      "epoch 1, step 657: train_loss 3.123; train_acc 0.250\n",
      "epoch 1, step 658: train_loss 2.270; train_acc 0.406\n",
      "epoch 1, step 659: train_loss 3.193; train_acc 0.188\n",
      "epoch 1, step 660: train_loss 3.233; train_acc 0.219\n",
      "epoch 1, step 661: train_loss 2.724; train_acc 0.375\n",
      "epoch 1, step 662: train_loss 2.974; train_acc 0.250\n",
      "epoch 1, step 663: train_loss 3.070; train_acc 0.312\n",
      "epoch 1, step 664: train_loss 3.469; train_acc 0.188\n",
      "epoch 1, step 665: train_loss 2.986; train_acc 0.250\n",
      "epoch 1, step 666: train_loss 3.438; train_acc 0.250\n",
      "epoch 1, step 667: train_loss 3.104; train_acc 0.312\n",
      "epoch 1, step 668: train_loss 3.010; train_acc 0.250\n",
      "epoch 1, step 669: train_loss 2.966; train_acc 0.281\n",
      "epoch 1, step 670: train_loss 2.718; train_acc 0.281\n",
      "epoch 1, step 671: train_loss 3.064; train_acc 0.219\n",
      "epoch 1, step 672: train_loss 3.016; train_acc 0.281\n",
      "epoch 1, step 673: train_loss 3.202; train_acc 0.156\n",
      "epoch 1, step 674: train_loss 2.932; train_acc 0.344\n",
      "epoch 1, step 675: train_loss 3.211; train_acc 0.125\n",
      "epoch 1, step 676: train_loss 2.819; train_acc 0.312\n",
      "epoch 1, step 677: train_loss 3.304; train_acc 0.219\n",
      "epoch 1, step 678: train_loss 3.300; train_acc 0.188\n",
      "epoch 1, step 679: train_loss 3.021; train_acc 0.250\n",
      "epoch 1, step 680: train_loss 3.019; train_acc 0.281\n",
      "epoch 1, step 681: train_loss 2.795; train_acc 0.219\n",
      "epoch 1, step 682: train_loss 3.007; train_acc 0.188\n",
      "epoch 1, step 683: train_loss 2.852; train_acc 0.250\n",
      "epoch 1, step 684: train_loss 2.937; train_acc 0.344\n",
      "epoch 1, step 685: train_loss 3.202; train_acc 0.250\n",
      "epoch 1, step 686: train_loss 2.531; train_acc 0.438\n",
      "epoch 1, step 687: train_loss 2.965; train_acc 0.250\n",
      "epoch 1, step 688: train_loss 3.187; train_acc 0.125\n",
      "epoch 1, step 689: train_loss 2.842; train_acc 0.250\n",
      "epoch 1, step 690: train_loss 2.980; train_acc 0.250\n",
      "epoch 1, step 691: train_loss 3.367; train_acc 0.250\n",
      "epoch 1, step 692: train_loss 2.567; train_acc 0.281\n",
      "epoch 1, step 693: train_loss 2.837; train_acc 0.281\n",
      "epoch 1, step 694: train_loss 3.022; train_acc 0.219\n",
      "epoch 1, step 695: train_loss 3.062; train_acc 0.156\n",
      "epoch 1, step 696: train_loss 3.148; train_acc 0.219\n",
      "epoch 1, step 697: train_loss 3.484; train_acc 0.219\n",
      "epoch 1, step 698: train_loss 2.607; train_acc 0.312\n",
      "epoch 1, step 699: train_loss 2.627; train_acc 0.344\n",
      "epoch 1, step 700: train_loss 2.937; train_acc 0.312\n",
      "epoch 1, step 701: train_loss 2.775; train_acc 0.250\n",
      "epoch 1, step 702: train_loss 3.024; train_acc 0.094\n",
      "epoch 1, step 703: train_loss 2.682; train_acc 0.281\n",
      "epoch 1, step 704: train_loss 2.516; train_acc 0.312\n",
      "epoch 1, step 705: train_loss 2.709; train_acc 0.375\n",
      "epoch 1, step 706: train_loss 3.165; train_acc 0.188\n",
      "epoch 1, step 707: train_loss 2.547; train_acc 0.281\n",
      "epoch 1, step 708: train_loss 3.110; train_acc 0.281\n",
      "epoch 1, step 709: train_loss 2.600; train_acc 0.312\n",
      "epoch 1, step 710: train_loss 3.318; train_acc 0.062\n",
      "epoch 1, step 711: train_loss 3.564; train_acc 0.125\n",
      "epoch 1, step 712: train_loss 2.754; train_acc 0.344\n",
      "epoch 1, step 713: train_loss 3.478; train_acc 0.219\n",
      "epoch 1, step 714: train_loss 3.658; train_acc 0.062\n",
      "epoch 1, step 715: train_loss 2.911; train_acc 0.312\n",
      "epoch 1, step 716: train_loss 2.974; train_acc 0.250\n",
      "epoch 1, step 717: train_loss 2.792; train_acc 0.281\n",
      "epoch 1, step 718: train_loss 2.535; train_acc 0.406\n",
      "epoch 1, step 719: train_loss 2.927; train_acc 0.312\n",
      "epoch 1, step 720: train_loss 2.545; train_acc 0.375\n",
      "epoch 1, step 721: train_loss 2.926; train_acc 0.281\n",
      "epoch 1, step 722: train_loss 3.194; train_acc 0.188\n",
      "epoch 1, step 723: train_loss 2.882; train_acc 0.250\n",
      "epoch 1, step 724: train_loss 3.024; train_acc 0.312\n",
      "epoch 1, step 725: train_loss 2.680; train_acc 0.375\n",
      "epoch 1, step 726: train_loss 3.089; train_acc 0.250\n",
      "epoch 1, step 727: train_loss 2.504; train_acc 0.375\n",
      "epoch 1, step 728: train_loss 2.847; train_acc 0.250\n",
      "epoch 1, step 729: train_loss 3.138; train_acc 0.219\n",
      "epoch 1, step 730: train_loss 2.770; train_acc 0.344\n",
      "epoch 1, step 731: train_loss 2.983; train_acc 0.250\n",
      "epoch 1, step 732: train_loss 2.419; train_acc 0.406\n",
      "epoch 1, step 733: train_loss 2.987; train_acc 0.281\n",
      "epoch 1, step 734: train_loss 2.994; train_acc 0.250\n",
      "epoch 1, step 735: train_loss 2.741; train_acc 0.312\n",
      "epoch 1, step 736: train_loss 2.751; train_acc 0.281\n",
      "epoch 1, step 737: train_loss 3.066; train_acc 0.188\n",
      "epoch 1, step 738: train_loss 3.132; train_acc 0.156\n",
      "epoch 1, step 739: train_loss 2.904; train_acc 0.312\n",
      "epoch 1, step 740: train_loss 2.633; train_acc 0.375\n",
      "epoch 1, step 741: train_loss 2.616; train_acc 0.375\n",
      "epoch 1, step 742: train_loss 2.864; train_acc 0.156\n",
      "epoch 1, step 743: train_loss 3.161; train_acc 0.219\n",
      "epoch 1, step 744: train_loss 3.151; train_acc 0.188\n",
      "epoch 1, step 745: train_loss 2.911; train_acc 0.250\n",
      "epoch 1, step 746: train_loss 2.890; train_acc 0.188\n",
      "epoch 1, step 747: train_loss 3.449; train_acc 0.188\n",
      "epoch 1, step 748: train_loss 3.181; train_acc 0.312\n",
      "epoch 1, step 749: train_loss 3.413; train_acc 0.156\n",
      "epoch 1, step 750: train_loss 2.238; train_acc 0.500\n",
      "epoch 1, step 751: train_loss 3.048; train_acc 0.219\n",
      "epoch 1, step 752: train_loss 2.704; train_acc 0.375\n",
      "epoch 1, step 753: train_loss 2.599; train_acc 0.250\n",
      "epoch 1, step 754: train_loss 3.056; train_acc 0.219\n",
      "epoch 1, step 755: train_loss 2.838; train_acc 0.375\n",
      "epoch 1, step 756: train_loss 3.230; train_acc 0.188\n",
      "epoch 1, step 757: train_loss 3.110; train_acc 0.219\n",
      "epoch 1, step 758: train_loss 2.928; train_acc 0.188\n",
      "epoch 1, step 759: train_loss 2.979; train_acc 0.219\n",
      "epoch 1, step 760: train_loss 2.992; train_acc 0.312\n",
      "epoch 1, step 761: train_loss 3.494; train_acc 0.156\n",
      "epoch 1, step 762: train_loss 2.653; train_acc 0.219\n",
      "epoch 1, step 763: train_loss 2.368; train_acc 0.375\n",
      "epoch 1, step 764: train_loss 2.645; train_acc 0.250\n",
      "epoch 1, step 765: train_loss 3.000; train_acc 0.219\n",
      "epoch 1, step 766: train_loss 2.685; train_acc 0.375\n",
      "epoch 1, step 767: train_loss 2.692; train_acc 0.438\n",
      "epoch 1, step 768: train_loss 2.695; train_acc 0.250\n",
      "epoch 1, step 769: train_loss 3.152; train_acc 0.219\n",
      "epoch 1, step 770: train_loss 2.852; train_acc 0.312\n",
      "epoch 1, step 771: train_loss 2.723; train_acc 0.344\n",
      "epoch 1, step 772: train_loss 2.634; train_acc 0.281\n",
      "epoch 1, step 773: train_loss 3.154; train_acc 0.094\n",
      "epoch 1, step 774: train_loss 2.898; train_acc 0.188\n",
      "epoch 1, step 775: train_loss 3.014; train_acc 0.188\n",
      "epoch 1, step 776: train_loss 2.676; train_acc 0.281\n",
      "epoch 1, step 777: train_loss 2.587; train_acc 0.375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 778: train_loss 3.537; train_acc 0.094\n",
      "epoch 1, step 779: train_loss 2.556; train_acc 0.344\n",
      "epoch 1, step 780: train_loss 2.702; train_acc 0.219\n",
      "epoch 1, step 781: train_loss 2.663; train_acc 0.375\n",
      "epoch 1, step 782: train_loss 2.627; train_acc 0.281\n",
      "epoch 1, step 783: train_loss 2.990; train_acc 0.219\n",
      "epoch 1, step 784: train_loss 2.596; train_acc 0.281\n",
      "epoch 1, step 785: train_loss 2.905; train_acc 0.250\n",
      "epoch 1, step 786: train_loss 3.225; train_acc 0.156\n",
      "epoch 1, step 787: train_loss 2.568; train_acc 0.250\n",
      "epoch 1, step 788: train_loss 2.824; train_acc 0.250\n",
      "epoch 1, step 789: train_loss 2.904; train_acc 0.281\n",
      "epoch 1, step 790: train_loss 2.560; train_acc 0.344\n",
      "epoch 1, step 791: train_loss 2.907; train_acc 0.156\n",
      "epoch 1, step 792: train_loss 2.686; train_acc 0.344\n",
      "epoch 1, step 793: train_loss 2.917; train_acc 0.156\n",
      "epoch 1, step 794: train_loss 2.917; train_acc 0.281\n",
      "epoch 1, step 795: train_loss 2.884; train_acc 0.406\n",
      "epoch 1, step 796: train_loss 3.016; train_acc 0.281\n",
      "epoch 1, step 797: train_loss 2.400; train_acc 0.375\n",
      "epoch 1, step 798: train_loss 2.459; train_acc 0.375\n",
      "epoch 1, step 799: train_loss 2.523; train_acc 0.281\n",
      "epoch 1, step 800: train_loss 2.755; train_acc 0.375\n",
      "epoch 1, step 801: train_loss 2.862; train_acc 0.250\n",
      "epoch 1, step 802: train_loss 3.340; train_acc 0.156\n",
      "epoch 1, step 803: train_loss 2.866; train_acc 0.219\n",
      "epoch 1, step 804: train_loss 2.839; train_acc 0.344\n",
      "epoch 1, step 805: train_loss 3.033; train_acc 0.156\n",
      "epoch 1, step 806: train_loss 2.776; train_acc 0.344\n",
      "epoch 1, step 807: train_loss 2.907; train_acc 0.281\n",
      "epoch 1, step 808: train_loss 2.955; train_acc 0.125\n",
      "epoch 1, step 809: train_loss 2.743; train_acc 0.188\n",
      "epoch 1, step 810: train_loss 2.737; train_acc 0.375\n",
      "epoch 1, step 811: train_loss 2.457; train_acc 0.406\n",
      "epoch 1, step 812: train_loss 2.999; train_acc 0.188\n",
      "epoch 1, step 813: train_loss 2.622; train_acc 0.344\n",
      "epoch 1, step 814: train_loss 2.115; train_acc 0.438\n",
      "epoch 1, step 815: train_loss 2.998; train_acc 0.250\n",
      "epoch 1, step 816: train_loss 2.574; train_acc 0.312\n",
      "epoch 1, step 817: train_loss 3.071; train_acc 0.250\n",
      "epoch 1, step 818: train_loss 2.645; train_acc 0.344\n",
      "epoch 1, step 819: train_loss 2.986; train_acc 0.188\n",
      "epoch 1, step 820: train_loss 2.786; train_acc 0.312\n",
      "epoch 1, step 821: train_loss 2.953; train_acc 0.250\n",
      "epoch 1, step 822: train_loss 2.683; train_acc 0.219\n",
      "epoch 1, step 823: train_loss 3.332; train_acc 0.156\n",
      "epoch 1, step 824: train_loss 2.790; train_acc 0.219\n",
      "epoch 1, step 825: train_loss 2.427; train_acc 0.438\n",
      "epoch 1, step 826: train_loss 3.116; train_acc 0.188\n",
      "epoch 1, step 827: train_loss 3.296; train_acc 0.125\n",
      "epoch 1, step 828: train_loss 3.022; train_acc 0.219\n",
      "epoch 1, step 829: train_loss 2.885; train_acc 0.188\n",
      "epoch 1, step 830: train_loss 3.010; train_acc 0.344\n",
      "epoch 1, step 831: train_loss 2.756; train_acc 0.281\n",
      "epoch 1, step 832: train_loss 3.094; train_acc 0.250\n",
      "epoch 1, step 833: train_loss 3.205; train_acc 0.219\n",
      "epoch 1, step 834: train_loss 2.787; train_acc 0.250\n",
      "epoch 1, step 835: train_loss 2.599; train_acc 0.344\n",
      "epoch 1, step 836: train_loss 2.647; train_acc 0.312\n",
      "epoch 1, step 837: train_loss 2.745; train_acc 0.312\n",
      "epoch 1, step 838: train_loss 2.824; train_acc 0.375\n",
      "epoch 1, step 839: train_loss 3.036; train_acc 0.156\n",
      "epoch 1, step 840: train_loss 3.143; train_acc 0.250\n",
      "epoch 1, step 841: train_loss 2.722; train_acc 0.312\n",
      "epoch 1, step 842: train_loss 2.865; train_acc 0.281\n",
      "epoch 1, step 843: train_loss 3.005; train_acc 0.156\n",
      "epoch 1, step 844: train_loss 2.931; train_acc 0.250\n",
      "epoch 1, step 845: train_loss 2.704; train_acc 0.188\n",
      "epoch 1, step 846: train_loss 2.848; train_acc 0.281\n",
      "epoch 1, step 847: train_loss 3.510; train_acc 0.188\n",
      "epoch 1, step 848: train_loss 3.127; train_acc 0.281\n",
      "epoch 1, step 849: train_loss 2.857; train_acc 0.250\n",
      "epoch 1, step 850: train_loss 3.029; train_acc 0.219\n",
      "epoch 1, step 851: train_loss 2.582; train_acc 0.344\n",
      "epoch 1, step 852: train_loss 2.901; train_acc 0.312\n",
      "epoch 1, step 853: train_loss 3.214; train_acc 0.281\n",
      "epoch 1, step 854: train_loss 2.947; train_acc 0.250\n",
      "epoch 1, step 855: train_loss 2.741; train_acc 0.188\n",
      "epoch 1, step 856: train_loss 2.630; train_acc 0.281\n",
      "epoch 1, step 857: train_loss 2.955; train_acc 0.344\n",
      "epoch 1, step 858: train_loss 2.704; train_acc 0.250\n",
      "epoch 1, step 859: train_loss 2.978; train_acc 0.250\n",
      "epoch 1, step 860: train_loss 2.958; train_acc 0.312\n",
      "epoch 1, step 861: train_loss 2.473; train_acc 0.375\n",
      "epoch 1, step 862: train_loss 2.813; train_acc 0.219\n",
      "epoch 1, step 863: train_loss 2.543; train_acc 0.375\n",
      "epoch 1, step 864: train_loss 2.726; train_acc 0.312\n",
      "epoch 1, step 865: train_loss 2.607; train_acc 0.375\n",
      "epoch 1, step 866: train_loss 2.611; train_acc 0.375\n",
      "epoch 1, step 867: train_loss 2.581; train_acc 0.281\n",
      "epoch 1, step 868: train_loss 2.749; train_acc 0.312\n",
      "epoch 1, step 869: train_loss 2.431; train_acc 0.469\n",
      "epoch 1, step 870: train_loss 2.259; train_acc 0.375\n",
      "epoch 1, step 871: train_loss 2.750; train_acc 0.312\n",
      "epoch 1, step 872: train_loss 3.219; train_acc 0.250\n",
      "epoch 1, step 873: train_loss 2.710; train_acc 0.344\n",
      "epoch 1, step 874: train_loss 2.928; train_acc 0.188\n",
      "epoch 1, step 875: train_loss 2.504; train_acc 0.344\n",
      "epoch 1, step 876: train_loss 2.389; train_acc 0.406\n",
      "epoch 1, step 877: train_loss 2.801; train_acc 0.250\n",
      "epoch 1, step 878: train_loss 3.086; train_acc 0.281\n",
      "epoch 1, step 879: train_loss 2.662; train_acc 0.281\n",
      "epoch 1, step 880: train_loss 2.768; train_acc 0.312\n",
      "epoch 1, step 881: train_loss 2.996; train_acc 0.219\n",
      "epoch 1, step 882: train_loss 2.457; train_acc 0.406\n",
      "epoch 1, step 883: train_loss 2.462; train_acc 0.375\n",
      "epoch 1, step 884: train_loss 2.718; train_acc 0.406\n",
      "epoch 1, step 885: train_loss 2.934; train_acc 0.188\n",
      "epoch 1, step 886: train_loss 3.463; train_acc 0.250\n",
      "epoch 1, step 887: train_loss 2.845; train_acc 0.312\n",
      "epoch 1, step 888: train_loss 2.710; train_acc 0.281\n",
      "epoch 1, step 889: train_loss 2.781; train_acc 0.188\n",
      "epoch 1, step 890: train_loss 2.936; train_acc 0.344\n",
      "epoch 1, step 891: train_loss 3.084; train_acc 0.281\n",
      "epoch 1, step 892: train_loss 3.027; train_acc 0.188\n",
      "epoch 1, step 893: train_loss 2.816; train_acc 0.344\n",
      "epoch 1, step 894: train_loss 3.164; train_acc 0.250\n",
      "epoch 1, step 895: train_loss 2.959; train_acc 0.250\n",
      "epoch 1, step 896: train_loss 3.087; train_acc 0.219\n",
      "epoch 1, step 897: train_loss 2.840; train_acc 0.281\n",
      "epoch 1, step 898: train_loss 2.978; train_acc 0.281\n",
      "epoch 1, step 899: train_loss 2.566; train_acc 0.375\n"
     ]
    }
   ],
   "source": [
    "trainer = ModelNetTrainer(cnet, train_loader, val_loader, optimizer, nn.CrossEntropyLoss(), 'svcnn', log_dir, num_views=1)\n",
    "trainer.train(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d33f4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c13693",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_81177/3484645345.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# STAGE 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlog_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_stage_2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcreate_folder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcnet_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMVCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcnn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_views\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mcnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_folder' is not defined"
     ]
    }
   ],
   "source": [
    "# STAGE 2\n",
    "log_dir = name+'_stage_2'\n",
    "create_folder(log_dir)\n",
    "cnet_2 = MVCNN(name, cnet, nclasses=40, cnn_name=cnn_name, num_views=num_views)\n",
    "del cnet\n",
    "\n",
    "# Adam Optimizer是对SGD的扩展，可以代替经典的随机梯度下降法来更有效地更新网络权重。\n",
    "optimizer = optim.Adam(cnet_2.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.9, 0.999))\n",
    "\n",
    "train_dataset = MultiviewImgDataset(train_path, scale_aug=False, rot_aug=False, num_models=n_models_train, num_views=num_views)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batchSize, shuffle=False, num_workers=0)# shuffle needs to be false! it's done within the trainer\n",
    "\n",
    "val_dataset = MultiviewImgDataset(val_path, scale_aug=False, rot_aug=False, num_views=num_views)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batchSize, shuffle=False, num_workers=0)\n",
    "print('num_train_files: '+str(len(train_dataset.filepaths)))\n",
    "print('num_val_files: '+str(len(val_dataset.filepaths)))\n",
    "trainer = ModelNetTrainer(cnet_2, train_loader, val_loader, optimizer, nn.CrossEntropyLoss(), 'mvcnn', log_dir, num_views=num_views)\n",
    "trainer.train(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "caeb46f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = '''\n",
    "\n",
    "\n",
    "'''\n",
    "fs = folders.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a6869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
